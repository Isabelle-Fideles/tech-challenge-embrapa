# Projeto: API Embrapa Uva e Vinho - POS Tech MLE

## DescriÃ§Ã£o
API para coleta estruturada de dados pÃºblicos da Embrapa, focando em produÃ§Ã£o, processamento, comercializaÃ§Ã£o, importaÃ§Ã£o e exportaÃ§Ã£o de uvas e vinhos.

## Tecnologias
- Python 3.12
- FastAPI
- SQLAlchemy
- SQLite (inicialmente)
- Alembic
- BeautifulSoup4

## Estrutura do Projeto - Um misto pragmÃ¡tico entre:
- **Clean Architecture** â†’ separaÃ§Ã£o de camadas lÃ³gicas (api/, core/, models/, schemas/, crud/)
- **Best Practices de FastAPI** â†’ organizada por "domÃ­nios" e com separaÃ§Ã£o por versÃ£o de API.

```
â”œğŸ“¦ app
â”œâ”€â”€ ğŸ“‚ alembic
â”œâ”€â”€ ğŸ“‚ api
â”‚   â””â”€â”€ ğŸ“‚ v1
â”‚       â”œâ”€â”€ ğŸ“„ api.py
â”‚       â”œâ”€â”€ ğŸ“‚ endpoints
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”‚   â””â”€â”€ ğŸ“„ scraping.py
â”‚       â””â”€â”€ ğŸ“„ __init__.py
â”œâ”€â”€ ğŸ“‚ core
â”‚   â””â”€â”€ ğŸ“„ exceptions.py
â”œâ”€â”€ ğŸ“‚ crud
â”‚   â””â”€â”€ ğŸ“„ scraping.py
â”œâ”€â”€ ğŸ“‚ db
â”‚   â”œâ”€â”€ ğŸ“„ base.py
â”‚   â””â”€â”€ ğŸ“„ session.py
â”œâ”€â”€ ğŸ“„ main.py
â”œâ”€â”€ ğŸ“‚ models
â”‚   â””â”€â”€ ğŸ“„ scraping.py
â”œâ”€â”€ ğŸ“‚ schemas
â”‚   â””â”€â”€ ğŸ“„ scraping.py
â”œâ”€â”€ ğŸ“‚ scraping
â”‚   â””â”€â”€ ğŸ“„ bs4_scraper.py
â””â”€â”€ ğŸ“‚ tests
ğŸ“„ create_db.py
ğŸ“„ embrapa.db
ğŸ“„ README.md
ğŸ“„ requirements.txt
```
---

## InstalaÃ§Ã£o WP
```bash
git clone https://github.com/seu-usuario/seu-projeto.git
cd seu-projeto
poetry install
poetry shell
```
---

## VariÃ¡veis de Ambiente (.env) WP
```bash 
DATABASE_URL=sqlite:///./app.db
SECRET_KEY=supersecret
```
---

## AtualizaÃ§Ã£o do DB SQLite Sempre que NecessÃ¡rio
```bash 
poetry run python create_db.py
```
---
## Rodando o Projeto
```bash 
uvicorn app.main:app --reload
```
---

## Testes WP
```bash 
pytest 
```
---

## ObservaÃ§Ãµes TÃ©cnicas
1. Toda entrada (requests) e saÃ­da (responses) sÃ£o validadas **por Schemas Pydantic**
2. PersistÃªncia usa **SQLAlchemy ORM** para garantir compatibilidade com mÃºltiplos bancos de dados.
3. Scraping Ã© feito usando **requests** para download de HTML e **BeautifulSoup4** para parsing dos dados.
4. **Caching inteligente** Ã© utilizado via `lru_cache (Least Recently Used)` para otimizar scraping repetitivo.
5. O projeto foi modularizado em camadas para garantir `manutenÃ§Ã£o`, `escalabilidade` e `boas prÃ¡ticas de desenvolvimento`.

---

## Arquitetura de Fluxo de Chamadas

Esta seÃ§Ã£o descreve o fluxo de funcionamento da API de Scraping da Embrapa.

O ciclo de uma requisiÃ§Ã£o Ã© composto por:

1. **RecepÃ§Ã£o da requisiÃ§Ã£o HTTP** (FastAPI)
2. **Chamadas de Endpoint** (`app/api/v1/endpoints/`)
3. **LÃ³gica de Scraping** (`app/scraping/bs4_scraper.py`)
4. **ValidaÃ§Ã£o e formataÃ§Ã£o de dados** (Pydantic Schemas)
5. **PersistÃªncia no Banco de Dados** (SQLAlchemy ORM)

---

## Fluxo detalhado passo a passo

| Etapa | DescriÃ§Ã£o | Arquivo |
|:------|:----------|:--------|
| 1 | FastAPI recebe a requisiÃ§Ã£o POST em `/api/v1/embrapa/producao` ou `/api/v1/embrapa/processamento` | `app/main.py` |
| 2 | A requisiÃ§Ã£o Ã© roteada para o mÃ³dulo correto de API (versÃ£o e prefixo) | `app/api/v1/api.py` |
| 3 | O endpoint especÃ­fico Ã© chamado: funÃ§Ã£o `embrapa_producao()` ou `embrapa_processamento()` | `app/api/v1/endpoints/scraping.py` |
| 4 | O serviÃ§o de scraping Ã© ativado para buscar os dados da Embrapa | `app/scraping/bs4_scraper.py` |
| 5 | O HTML da pÃ¡gina Ã© baixado (requests) e parseado (BeautifulSoup) usando `parse_table` ou `parse_import_export_table` | `app/scraping/bs4_scraper.py` |
| 6 | Se os dados jÃ¡ existirem no banco, sÃ£o carregados via `get_producao()` ou `get_processamento()` | `app/crud/scraping.py` |
| 7 | Se os dados nÃ£o existirem, o scraping Ã© salvo no banco com `create_producao()` ou `create_processamento()` | `app/crud/scraping.py` |
| 8 | A resposta Ã© formatada para JSON conforme o schema Pydantic | `app/schemas/scraping.py` |
| 9 | A resposta formatada Ã© devolvida ao usuÃ¡rio pela API | (Resposta HTTP) |

---


## LicenÃ§a
MIT License.
